{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from automl import AutoML\n",
    "from automl import wrappers\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [22:14, 667.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1334.3654420375824 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# instance automl object and read the data by its path\n",
    "# during the initialization it will perform the training and model evaluation\n",
    "# the important_future_timesteps parameter indicates the time steps that the models will be evaluated.\n",
    "data_path = '../data/test_ex_1.csv'\n",
    "start_time = time.time()\n",
    "ml = AutoML(data_path, important_future_timesteps=[1,2,5], wrapper_constructors=[wrappers.ProphetWrapper])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prophet0': {'default': {'wape': 0.06352578264936852,\n",
       "   'rmse': 5.3382672913378775},\n",
       "  '0.1': {'wql': 0.13776415383237553},\n",
       "  '0.5': {'wql': 0.13620595535691202},\n",
       "  '0.9': {'wql': 0.05635976649526172}},\n",
       " 'Prophet1': {'default': {'wape': 0.06306066163126504,\n",
       "   'rmse': 5.334946324844748},\n",
       "  '0.1': {'wql': 0.13621476570525337},\n",
       "  '0.5': {'wql': 0.13491722425462638},\n",
       "  '0.9': {'wql': 0.05490197225720121}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the evaluation results after choose the model\n",
    "ml.evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<automl.wrappers.ProphetWrapper.ProphetWrapper at 0x2464acd4040>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the oldest lag chosen by the automl\n",
    "# this information is important because it is the minimun data size to make new predictions\n",
    "ml.oldest_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next prediction: [[89.27060351 89.48528391 89.73331211 90.01634539 90.33188142]]\n"
     ]
    }
   ],
   "source": [
    "# predict the next time step based on the last trained data\n",
    "next_value = ml.next(5)\n",
    "print('Next prediction:', next_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next predictions: [[88.19292184 88.34009649 88.48410621]\n",
      " [88.34009649 88.48410621 88.62608743]\n",
      " [88.48398737 88.62596915 88.76939984]\n",
      " [88.62608743 88.76952139 88.91999335]\n",
      " [88.76952139 88.91999335 89.08455835]\n",
      " [88.91999335 89.08455835 89.2707697 ]\n",
      " [89.08441324 89.27060351 89.48528391]\n",
      " [89.27060351 89.48528391 89.73331211]]\n"
     ]
    }
   ],
   "source": [
    "# predict values from a horizon of at least past lag length\n",
    "df = pd.read_csv(data_path)\n",
    "X = df.iloc[-ml.oldest_lag-5:]\n",
    "next_values = ml.predict(X, 3)\n",
    "\n",
    "print('Next predictions:', next_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
