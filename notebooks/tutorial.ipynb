{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import automl\n",
    "from automl import AutoML\n",
    "from automl import wrappers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SARIMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:10,  2.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# instance automl object and read the data by its path\n",
    "# during the initialization it will perform the training and model evaluation\n",
    "# the important_future_timesteps parameter indicates the time steps that the models will be evaluated.\n",
    "data_path = '../data/test_ex_1.csv'\n",
    "ml = AutoML(data_path, important_future_timesteps=[1,2,5], wrapper_constructors=[wrappers.SarimaWrapper], jobs=-1, nlags=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SARIMA0': {'default': {'wape': 0.04968046097433211,\n",
       "   'rmse': 4.426069213787566}},\n",
       " 'SARIMA1': {'default': {'wape': 0.0479467657857178,\n",
       "   'rmse': 4.302835102282805}},\n",
       " 'SARIMA2': {'default': {'wape': 0.04840152338438849,\n",
       "   'rmse': 4.335189662818897}},\n",
       " 'SARIMA3': {'default': {'wape': 0.04968048286077216,\n",
       "   'rmse': 4.426070632226787}},\n",
       " 'SARIMA4': {'default': {'wape': 0.049680460974332236,\n",
       "   'rmse': 4.4260692137875735}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the evaluation results after choose the model\n",
    "ml.evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the oldest lag chosen by the automl\n",
    "# this information is important because it is the minimun data size to make new predictions\n",
    "ml.oldest_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next prediction: [72.10628294 72.07618965 72.18126918 72.15197348 72.25714662]\n"
     ]
    }
   ],
   "source": [
    "# predict the next time step based on the last trained data\n",
    "next_value = ml.next(5)\n",
    "print('Next prediction:', next_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next predictions: [[72.10628294 72.07618965 72.18126918]\n",
      " [72.10628294 72.07618965 72.18126918]\n",
      " [72.10628294 72.07618965 72.18126918]\n",
      " [72.10628294 72.07618965 72.18126918]\n",
      " [72.10628294 72.07618965 72.18126918]\n",
      " [72.10628294 72.07618965 72.18126918]\n",
      " [72.10628294 72.07618965 72.18126918]\n",
      " [72.10628294 72.07618965 72.18126918]]\n"
     ]
    }
   ],
   "source": [
    "# predict values from a horizon of at least past lag length\n",
    "df = pd.read_csv(data_path)\n",
    "X = df.iloc[-ml.oldest_lag-5:]\n",
    "next_values = ml.predict(X, 3)\n",
    "\n",
    "print('Next predictions:', next_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
